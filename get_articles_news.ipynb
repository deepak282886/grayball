{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3859981-4abe-406c-843e-0d7c7e49a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob \n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddb8ca-df24-41ea-a9e3-662dead9a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(\"/Users/deepakyadav/Downloads/feature_url.csv\")\n",
    "url_list2 = list(df_features[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17495169-27e2-412d-bec0-609e6aed7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"feat_articles/\", exist_ok=True)\n",
    "for jj in tqdm(url_list2):\n",
    "  try:\n",
    "    full_jj = \"https://www.espncricinfo.com\" + jj\n",
    "    webpage = requests.get(full_jj)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    save_name = jj.split(\"/\")[-1].split(\"-\")[-1]\n",
    "    text = str(soup).split('\"articleBody\":\"')[1].split('\",\"articleSection')[0]\n",
    "    with open(f\"feat_articles/{save_name}.txt\", \"w\") as f:\n",
    "      f.write(text)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74a914-bbe7-41d0-a4f6-2fde7bd10e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"final_articles/\", exist_ok=True)\n",
    "files = glob.glob(f\"feat_articles/*\")\n",
    "for i in files:\n",
    "  filename = i.split('/')[-1]\n",
    "  with open(i, \"r\") as f:\n",
    "    text = f.read()\n",
    "    text2 = str({\"text\" : text})\n",
    "    with open(f'final_articles/{filename}', \"w\") as f:\n",
    "      f.write(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cdd14-d046-4d26-ae21-62ba724b770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(\"/Users/deepakyadav/Downloads/news_url_2.csv\")\n",
    "url_list2 = list(df_features[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfbd52-3604-472d-87cd-f51de48f090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"news_articles/\", exist_ok=True)\n",
    "for jj in url_list2:\n",
    "  try:\n",
    "    full_jj = \"https://www.espncricinfo.com\" + jj\n",
    "    webpage = requests.get(full_jj)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    save_name = jj.split(\"/\")[-1].split(\"-\")[-1]\n",
    "    text = str(soup).split('\"articleBody\":\"')[1].split('\",\"articleSection')[0]\n",
    "    with open(f\"news_articles/{save_name}.txt\", \"w\") as f:\n",
    "      f.write(text)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a5872-b327-4bef-b2d3-274ed6b0a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(\"/Users/deepakyadav/Downloads/news_url_1.csv\")\n",
    "url_list2 = list(df_features[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267eb97-b18c-49de-9965-c67c990086f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"news_articles/\", exist_ok=True)\n",
    "for jj in tqdm(url_list2):\n",
    "  try:\n",
    "    full_jj = \"https://www.espncricinfo.com\" + jj\n",
    "    webpage = requests.get(full_jj)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    save_name = jj.split(\"/\")[-1].split(\"-\")[-1]\n",
    "    text = str(soup).split('\"articleBody\":\"')[1].split('\",\"articleSection')[0]\n",
    "    with open(f\"news_articles/{save_name}.txt\", \"w\") as f:\n",
    "      f.write(text)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a51e8-b54e-4c07-8e53-a8040364d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"final_articles/\", exist_ok=True)\n",
    "files = glob.glob(f\"news_articles/*\")\n",
    "for i in files:\n",
    "  filename = i.split('/')[-1]\n",
    "  with open(i, \"r\") as f:\n",
    "    text = f.read()\n",
    "    text2 = str({\"text\" : text})\n",
    "    with open(f'final_articles/{filename}', \"w\") as f:\n",
    "      f.write(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eebb81-f9ea-44a5-a5f6-914c73105a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing unwanted characters and formating\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"&quot;\", r'\"', text) \n",
    "    text = re.sub(r\"&apos;\", r\"'\", text)\n",
    "    text = re.sub(r\"&amp;\", r\"&\", text)  \n",
    "    text = re.sub(r\"&gt;\", r\">\", text)\n",
    "    text = re.sub(r\"&lt;\", r\"<\", text)\n",
    "    text = re.sub(r\"\\\\n|\\\\t|\\\\r\", \" \", text)\n",
    "    text = re.sub(r\"\\\\(.)\", r\"\\1\", text)\n",
    "    text = re.sub(r\"&copy;\", r\"©\", text)\n",
    "    \n",
    "    text = re.sub(\"'text'\", \"\", text)\n",
    "    text = re.sub(r'\"text\"', '', text)\n",
    "    text = re.sub(r'&nbsp;', '', text)\n",
    "    \n",
    "    text = re.sub(r'{:', '', text)\n",
    "    text = re.sub(r'}', '', text)\n",
    "    text = re.sub(r\"© \\S+ ?\", \"\", text)\n",
    "    text = re.sub(r\"© \\S+ ?\", \"\", text)\n",
    "    \n",
    "    text = re.sub(r\"ESPN\", \"\", text)\n",
    "    text = re.sub(r\"espn\", \"\", text)\n",
    "    text = re.sub(r\"Cricinfo\", \"\", text)\n",
    "    text = re.sub(r\"cricinfo\", \"\", text)\n",
    "    text = re.sub(r\"Cricbuzz\", \"\", text)\n",
    "    text = re.sub(r\"cricbuzz\", \"\", text)\n",
    "    text = re.sub(r\"\\.'\\s*\", \"\", text)\n",
    "    text = re.sub(r'\\\\\"', '\"', text)\n",
    "    text = re.sub(r\"([.?!,])(\\\"|\\'|\\w)\", r\"\\1 \\2\", text) \n",
    "    text = re.sub(r\"(\\\"|\\w)([.?!,])\", r\"\\1 \\2\", text)\n",
    "    text = re.sub(r\"[^.?!]$\", r\"\\0.\", text)\n",
    "    text = re.sub(r\"\\x00\", r\"\", text)\n",
    "    \n",
    "    text = re.sub(r'. \".', r'. \"', text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"^\\\"|\\\"$\", \"\", text)\n",
    "    \n",
    "    # Consolidate consecutive quotes\n",
    "    text = re.sub(r\"''+\", r\"'\", text)  \n",
    "    text = re.sub(r'\"\"+', r'\"', text)\n",
    "    text = re.sub(r\"^'\\s*\", \"\", text)\n",
    "    \n",
    "    # Normalize all whitespace to single spaces  \n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a4f3f-d0e7-4959-a784-6f2ae899dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"final_articles/*\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ea1cb-6306-4aba-9d29-8fc3e20b4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(files):\n",
    "    filename = i.split(\"/\")[-1]\n",
    "    with open(i, \"r\") as f:\n",
    "        tx = f.read()\n",
    "    tx = clean_text(tx)\n",
    "    text2 = str({\"text\" : tx})\n",
    "    with open(f\"final_articles_clean/{filename}\", \"w\") as f:\n",
    "        f.write(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f92d2-0fb3-4fd4-b95f-df87a7deb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"final_articles_clean/*\")\n",
    "len(files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
